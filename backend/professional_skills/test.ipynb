{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 156)) while a minimum of 1 is required by TfidfTransformer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASUS\\Desktop\\Final_RP\\2023-098\\backend\\professional_skills\\test.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/Final_RP/2023-098/backend/professional_skills/test.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Call the function to get skills\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/Final_RP/2023-098/backend/professional_skills/test.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m skills \u001b[39m=\u001b[39m scrape_linkedin_skills(linkedin_profile_url)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/Final_RP/2023-098/backend/professional_skills/test.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m predicted_category \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(fitted_vectorizer\u001b[39m.\u001b[39;49mtransform(skills))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/Final_RP/2023-098/backend/professional_skills/test.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicted Job Category: \u001b[39m\u001b[39m{\u001b[39;00mpredicted_category[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Desktop/Final_RP/2023-098/backend/professional_skills/test.ipynb#W0sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2158\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2155\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, msg\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2157\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mtransform(raw_documents)\n\u001b[1;32m-> 2158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tfidf\u001b[39m.\u001b[39;49mtransform(X, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1710\u001b[0m, in \u001b[0;36mTfidfTransformer.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Transform a count matrix to a tf or tf-idf representation.\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m \n\u001b[0;32m   1696\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1708\u001b[0m \u001b[39m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   1709\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1710\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1711\u001b[0m         X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES, copy\u001b[39m=\u001b[39;49mcopy, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1712\u001b[0m     )\n\u001b[0;32m   1713\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m   1714\u001b[0m         X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 156)) while a minimum of 1 is required by TfidfTransformer."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pickle\n",
    "from ScrapeLinkedIn import scrape_linkedin_skills\n",
    "\n",
    "model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
    "fitted_vectorizer = pickle.load(open(\"fitted_vectorizer.pkl\", \"rb\"))\n",
    "linkedin_profile_url = 'https://www.linkedin.com/in/chanuxbro/'\n",
    "\n",
    "def scrape_linkedin_skills(linkedin_profile_url):\n",
    "    api_key = '9D-mKt3-m74E0Kacy5Z89A'\n",
    "    api_endpoint = 'https://nubela.co/proxycurl/api/v2/linkedin'\n",
    "    headers = {'Authorization': 'Bearer ' + api_key}\n",
    "\n",
    "    response = requests.get(api_endpoint,\n",
    "                            params={'url': linkedin_profile_url, 'skills': 'include'},\n",
    "                            headers=headers)\n",
    "\n",
    "    profile_data = response.json()\n",
    "\n",
    "    if 'skills' in profile_data:\n",
    "        return profile_data['skills']\n",
    "        \n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Example LinkedIn profile URL\n",
    "linkedin_profile_url = 'https://www.linkedin.com/in/chanuxbro/'\n",
    "\n",
    "# Call the function to get skills\n",
    "skills = scrape_linkedin_skills(linkedin_profile_url)\n",
    "\n",
    "predicted_category = model.predict(fitted_vectorizer.transform(skills))\n",
    "result = f\"Predicted Job Category: {predicted_category[0]}\"\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
